感知层、决策层、控制层

算法、系统、云平台 车辆端：上层（算法）->传感、感知、决策：下层（操作系统/硬件平台）->云端，需要有一个无人驾驶的平台，囊括高精度地图、模型训练、模拟计算和数据存储等内容。

一、定位 定位技术：GPS 多星GPS的精度大约为1-2米，满足不了要求 RTK（GPS技术）：通过地面基站去纠正卫星信号，精度达到分米级别或者更低，但成本高 PPP（精密单点定位GPS技术）：基于全球卫星的联网系统，通过互联网发布卫星纠正信号 定位技术：激光雷达（LiDAR），能触及100-200米的距离，能准确得到空间中的点云 定位技术：高精地图（HD MAP），通过与激光雷达的数据进行精确匹配，可以将车辆定位上升到厘米级别

高精地图的制作： 底层是网格地图，网格地图是通过使用激光雷达扫描回来的，精度可达5厘米 网格地图之上，是道路的标签，reference line，加上语义信息，精确到车道，标示出lanes 车道之上再做一些语义标签，比如限速、红绿灯这样的tag

定位技术：视觉 传统方法：双目视觉导航，左右两边的后侧图进行三角成像，得出空间中深度点的信息。 后续发展：实现单目视觉导航，并通过加上IMU进行快速信息更新，可以得到很精准的位置更新

定位技术：轮速计 定位技术：传感器融合 通过IMU和轮速计，得到车辆初始的位置，而GPS则可以不断纠偏，把错误率控制在一定的范围，比如GPS是厘米级的，那么精度就能保证在厘米级别，同时再加上激光雷达和高精地图的匹配，得出一个最终的很精准的位置。

二、感知 感知就是理解环境，要做感知，需要的是一个数据集（Datasets）。 无人驾驶行业有一套通用的数据集，KITTI数据集，包括双目视觉的数据，定位导航的数据等 感知技术：物体检测 传统方法主要是针对固定物体的检测。一般的方法是HOG（ 方向梯度直方图），然后再加一个SVM的分类器。而对于动态物体的检测，主要使用的是DPM模型的方法，先把手和脚识别出来，再进行组合。 感知技术：场景 人行道是一个场景，道路是一个场景，在场景中对不同的物体进行分类，是一个很重要的问题。传统的方法是采用CRF（ 条件随机场），基本原理在于图像都是由像素点组成的，若两个像素点都比较像车，那就把二者连接起来，形成对车辆的识别。 另外，就是我们所说的光流（Optical Flow），光流是针对2D图像来说的，如果说一个图片流到另外一个图片，都是2D的物体移动，那就用光流来做。如果是3D的物体流动，那我们就用场景流（Scene Flow），场景流在传统的方法就是使用的是SGBM，利用的是双目成像的技术，把左图和右图合起来提取出空间的点，用光流在上面做，就能把场景的流动分析出来。 感知技术：物体追踪 里面用到的是马尔可夫链的解决方案，这个技术叫做MDP，跟踪一个人，随时跟踪其下一个动作，预测其下一个动作。在物体识别方面，有两个非常有效的模型。 一个是Faster R-CNN，它会将兴趣点框出来，然后再进行物体识别，找到是不是你想要识别的物体；另一个是更为快速的SSD，也是将图中的物体识别出来。 而在场景分类方面，运用深度学习的方法则使用的是另一种模型，被称为PSPnet（语义分割）。这是金字塔型的场景分解模型，将一个场景不断地压缩，把类似的物体聚类，然后再做判断。

三、决策和控制 交通预测其实可以分成两个问题：一个是分类问题，另一个是回归的问题。分类问题要了解的是行人到底是过马路还是不过马路，回归问题就更复杂一些，如果行人是过马路，那么针对其过马路的速度是多少，需要做一个预测。 路径规划也是比较有趣的，因为这对无人车来说是一个比较特殊的问题，因为对于普通的车辆来说，只要知道这是哪条路就行了，而不需要知道这是哪一条车道。 因为每条路都有不同的车道，那我们把车道标出不同的节点，不同的节点连接在一起，就变成了一条车道。通过某种方式（Dijkstra和A*）找到最短车道，就能得到最优解。 有了全局的路径规划以后，我们就需要进行行为决策。因为道路场景非常复杂，可以分成几十个不同的场景——左右车道、丁字路口等等，需要做场景组合决策。 然后是动作的规划，包括加速、减速、转向等等，速度规划主要使用了ST-graph工具来做，路径规划主要是动态编程来实现。

而最后的反馈控制则是由车厂来做，而且很多车厂采取的方案是不一样的。实现反馈控制的一般有双轮模型和PID控制模型，后者实现起来比较顺畅。

端系统： 任何一个复杂的系统都需要一个操作系统来辅助它实现功能，这样才不至于混乱。 在处理器中，其实运行了上文所述的各类算法，包括感知、定位、全局路径规划等算法。然后再实现对车辆本身的控制，包括动作控制、方向控制。 ROS-机器人操作系统 特点： 单一主节点，很容易整体崩溃。（解决方案：可以用Zookeeper机制来做，设置多个主节点。） 通信非常低效。（解决方案：可以用共享内存的方法来做。） 不是很安全，比如开一个恶意节点不断去损耗资源，很容易造成整体系统的崩溃。 （解决方案：这个问题可以使用Linux Container的技术来解决。） 硬件平台当然也是不可或缺的。其前端有很多传感器，信号传输进来后，有一个计算平台进行接收，处理完成后再通过CAN-BUS，把控制信号传给车辆控制系统。

功耗高和计算单元小型化

云平台： 云平台底层就是存储和计算。我们有一个开源的项目叫做Alluxio，基本上就把磁盘存储给管理起来了，这是一个分布式的存储管理器；在其上，我们运用了异构计算，不同的作业依赖的处理器也不一样，所以会有GPU、CPU和FPGA；当然，为一个处理器写一套单独的程序，太复杂了，所以在其上统一搭载了OpenCL，对程序进行统一管理；分布式计算也需要一个管理平台，我们采用了Spark平台——比较通用、功能很多。再在这个平台上搭建高精地图、模拟计算和模型计算等作业。 在计算层面，我们运用了Apache Yarn这个分布式系统管理器通过Spark把作业分发下去，每个Spark的节点都有多个容器（Container），容器上会跑一些 OpenCL 的 Kernel，OpenCL 可以跑在 GPU 上，也可以跑在FPGA上。这个平台的可扩展性非常强，模型训练所需的时间会随着GPU数量的增加而线性减少。

首先是模拟计算。比如你新开发了一个程序，想要试试新的算法是不是好用，但是不可能每次都实车验证，因为成本高，而且覆盖的场景很少。所以一般采用的是模拟计算的方式：游戏平台和真实数据回放，更多是采用后者的形式。这里有一个问题，单机回放必须要回放实际的数据，比如谷歌无人车累计有8年的数据，如果单机计算需要很长时间，这显然不可取。所以这里采用了Spark Driver的系统，可以并行处理，把作业分发下去，通过Linux pipe把每一个ROS Node节点打出来做一个回放，数据再回收到Spark Driver里去。只要给的节点够多，几十分钟就可以验证一套算法。 第二个是高精地图的制作。这是个很复杂的工作，首先是裸数据，然后从裸数据得出一个点云的数据，点云和点云之间要做一个对齐，对齐之后要把反射率的数据填到里面，然后再加一些语义的信息等。用分布式平台来做高精地图的生产，最大的计算量部分集中在点云的生产和对齐上，用异构计算可以很好地完成这些作业。
